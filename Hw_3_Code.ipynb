{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###Part 2: CODING\n",
        "\n",
        "Applying spam classification code from the Problem 4 at the end of the Chapter 3 to a different dataset.\n",
        "\n",
        "The chosen dataset is a Kaggle **\"Email Spam Classification Dataset\"** which has a .csv file containing related information of 5172 randomly picked email files and their respective labels for spam or not-spam classification.\n",
        "\n",
        "The steps to follow (as shown in Chapter 3 Problem 4) are:\n",
        "\n",
        "\n",
        "* _Split the datasets into a training set and a test set._\n",
        "* _Write a data preparation pipeline to convert each email into a feature vector._\n",
        "* _Finally, try out several classifiers and see if you can build a great spam classifier, with both high recall and high precision_"
      ],
      "metadata": {
        "id": "lmV472-DwrPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"balaka18/email-spam-classification-dataset-csv\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al2T9rY7ru-v",
        "outputId": "52a975e2-74c8-488a-e84e-6cc866da855c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/balaka18/email-spam-classification-dataset-csv/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# dataset path\n",
        "dataset_path = '/root/.cache/kagglehub/datasets/balaka18/email-spam-classification-dataset-csv/versions/1/emails.csv'\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(dataset_path)\n",
        "print(data.head())  # Inspect the first few rows to understand the data format\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(train_set.info())\n",
        "print(test_set.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHp5dR7UsWic",
        "outputId": "d00fc631-408b-48ce-bd11-8ab3cff088d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Email No.  the  to  ect  and  for  of    a  you  hou  ...  connevey  jay  \\\n",
            "0   Email 1    0   0    1    0    0   0    2    0    0  ...         0    0   \n",
            "1   Email 2    8  13   24    6    6   2  102    1   27  ...         0    0   \n",
            "2   Email 3    0   0    1    0    0   0    8    0    0  ...         0    0   \n",
            "3   Email 4    0   5   22    0    5   1   51    2   10  ...         0    0   \n",
            "4   Email 5    7   6   17    1    5   2   57    0    9  ...         0    0   \n",
            "\n",
            "   valued  lay  infrastructure  military  allowing  ff  dry  Prediction  \n",
            "0       0    0               0         0         0   0    0           0  \n",
            "1       0    0               0         0         0   1    0           0  \n",
            "2       0    0               0         0         0   0    0           0  \n",
            "3       0    0               0         0         0   0    0           0  \n",
            "4       0    0               0         0         0   1    0           0  \n",
            "\n",
            "[5 rows x 3002 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 4137 entries, 3164 to 860\n",
            "Columns: 3002 entries, Email No. to Prediction\n",
            "dtypes: int64(3001), object(1)\n",
            "memory usage: 94.8+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1035 entries, 1566 to 2142\n",
            "Columns: 3002 entries, Email No. to Prediction\n",
            "dtypes: int64(3001), object(1)\n",
            "memory usage: 23.7+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Separating the features and the target variable\n",
        "X_train = train_set.drop(columns=['Email No.', 'Prediction'])\n",
        "y_train = train_set['Prediction']\n",
        "X_test = test_set.drop(columns=['Email No.', 'Prediction'])\n",
        "y_test = test_set['Prediction']\n",
        "\n",
        "# Creating and training the logistic regression model\n",
        "model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the test set results\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs1USqsqsh6k",
        "outputId": "4bafc478-5c7d-48c6-9a2c-f0e93b86e325"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.97\n",
            "Precision: 0.94\n",
            "Recall: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "trying a validation check to ensure I have not made any errors while trying to follow the steps.\n",
        "\n"
      ],
      "metadata": {
        "id": "yXC2MJfutg5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--------------------"
      ],
      "metadata": {
        "id": "O6PBAXkAtS2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from nltk.stem import SnowballStemmer\n",
        "import re\n",
        "\n",
        "# Example function to clean and preprocess text\n",
        "def clean_email_text(email):\n",
        "    email = email.lower()  # convert to lowercase\n",
        "    email = re.sub(r'https?://\\S+|www\\.\\S+', 'URL', email)  # replace URLs\n",
        "    email = re.sub(r'\\d+', 'NUMBER', email)  # replace numbers\n",
        "    email = re.sub(r'\\W', ' ', email)  # remove punctuation\n",
        "    stemmer = SnowballStemmer('english')\n",
        "    email = ' '.join(stemmer.stem(word) for word in email.split())  # stemming\n",
        "    return email\n",
        "\n",
        "# Vectorization using CountVectorizer to mimic creating binary or count vectors by creating a pipeline\n",
        "vectorizer = CountVectorizer(preprocessor=clean_email_text, binary=True)  # Use binary=False for counts\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('vectorizer', vectorizer),\n",
        "    ('classifier', LogisticRegression(max_iter=1000))\n",
        "])\n"
      ],
      "metadata": {
        "id": "RAsXp1bRuAFt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data (already shown previously)\n",
        "X_train = train_set.drop(['Email No.', 'Prediction'], axis=1)\n",
        "y_train = train_set['Prediction']\n",
        "X_test = test_set.drop(['Email No.', 'Prediction'], axis=1)\n",
        "y_test = test_set['Prediction']\n",
        "\n",
        "# Fit multiple models to compare\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100),\n",
        "    'SVC': SVC(kernel='linear')\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    results[name] = (accuracy, precision, recall)\n",
        "\n",
        "for name, scores in results.items():\n",
        "    print(f\"{name} - Accuracy: {scores[0]:.2f}, Precision: {scores[1]:.2f}, Recall: {scores[2]:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcF_-egTuCFg",
        "outputId": "5219c276-8609-44b2-e05b-111acff8ded0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Accuracy: 0.97, Precision: 0.94, Recall: 0.96\n",
            "Random Forest - Accuracy: 0.98, Precision: 0.96, Recall: 0.96\n",
            "SVC - Accuracy: 0.96, Precision: 0.92, Recall: 0.94\n"
          ]
        }
      ]
    }
  ]
}